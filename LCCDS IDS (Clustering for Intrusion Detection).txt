from sklearn.cluster import DBSCAN
from sklearn.preprocessing import StandardScaler

# Load dataset
data = pd.read_csv(r'C:\Users\91837\Desktop\kddcup.data', header=None)

# Define column names
columns = ["duration", "protocol_type", "service", "flag", "src_bytes", "dst_bytes", "land", "wrong_fragment", 
           "urgent", "hot", "num_failed_logins", "logged_in", "num_compromised", "root_shell", "su_attempted",
           "num_root", "num_file_creations", "num_shells", "num_access_files", "num_outbound_cmds", "is_host_login",
           "is_guest_login", "count", "srv_count", "serror_rate", "srv_serror_rate", "rerror_rate", "srv_rerror_rate",
           "same_srv_rate", "diff_srv_rate", "srv_diff_host_rate", "dst_host_count", "dst_host_srv_count", 
           "dst_host_same_srv_rate", "dst_host_diff_srv_rate", "dst_host_same_src_port_rate", 
           "dst_host_srv_diff_host_rate", "dst_host_serror_rate", "dst_host_srv_serror_rate", 
           "dst_host_rerror_rate", "dst_host_srv_rerror_rate"]

data.columns = columns

# Extract features (X)
X = data.drop(['class'], axis=1)

# Standardize features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Apply DBSCAN for clustering
dbscan = DBSCAN(eps=0.5, min_samples=5)
y_pred_dbscan = dbscan.fit_predict(X_scaled)

# -1 indicates noise points, which can be considered as anomalies
print(f"Number of clusters found: {len(set(y_pred_dbscan)) - (1 if -1 in y_pred_dbscan else 0)}")
print(f"Sample of predicted clusters: {y_pred_dbscan[:10]}")

